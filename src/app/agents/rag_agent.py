"""
RAG Agent
ä½¿ç”¨æ‰€æœ‰ç»„ä»¶å®ç°å®Œæ•´çš„ RAG åŠŸèƒ½

æ–°å¢èƒ½åŠ›ï¼š
- Agent æ„å›¾åˆ†æï¼šåˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆæ£€ç´¢å†³ç­–
- åŠ¨æ€ç­–ç•¥è°ƒæ•´ï¼šæ ¹æ®å†³ç­–ç»“æœè°ƒæ•´æ£€ç´¢ç­–ç•¥
"""

import asyncio
import json
import traceback
from typing import Dict, List, Optional, Tuple
from dashscope import Generation
from src.app.agents.base_agent import BaseAgent
from src.app.components.retrievers import BaseRetriever, HybridVectorRetriever
from src.app.components.generators import BaseGenerator, LLMGenerator
from src.app.components.classifier import BaseClassifier, GovClassifier
from src.app.components.memory import BaseMemory, ConversationMemory
from src.app.components.quality.answer_validator import AnswerValidator
from src.app.agents.models.agent_decision import (
    AgentDecision,
    AgentDecisionType,
    RetrievalStrategy
)
from src.app.infra.utils.logger import get_logger
from src.app.infra.llm.multi_model_service import get_light_llm_service

logger = get_logger(__name__)


class RagAgent(BaseAgent):
    """
    RAG Agent

    ä½¿ç”¨æ‰€æœ‰ç»„ä»¶å®ç°å®Œæ•´åŠŸèƒ½ï¼š
    - Generatorï¼šç”Ÿæˆå›ç­”
    - Classifierï¼šåˆ†ç±»é—®æ”¿ç±»å‹
    - Memoryï¼šç®¡ç†å¯¹è¯å†å²
    - Retrieverï¼šæ£€ç´¢ç›¸å…³æ¡ˆä¾‹
    """

    def __init__(
        self,
        retriever: Optional[BaseRetriever] = None,
        generator: Optional[BaseGenerator] = None,
        classifier: Optional[BaseClassifier] = None,
        memory: Optional[BaseMemory] = None,
        validator: Optional[AnswerValidator] = None
    ):
        super().__init__(name="RagAgent")

        # ä¾èµ–æ³¨å…¥ï¼šæ‰€æœ‰ç»„ä»¶
        self.retriever = retriever or HybridVectorRetriever()
        self.generator = generator or LLMGenerator()
        self.classifier = classifier or GovClassifier()
        self.memory = memory or ConversationMemory()
        self.validator = validator or AnswerValidator()

        logger.info("âœ… RagAgent åˆå§‹åŒ–å®Œæˆï¼Œç»„ä»¶åŠ è½½ï¼š")
        logger.info(f"  - Retriever: {type(self.retriever).__name__}")
        logger.info(f"  - Generator: {type(self.generator).__name__}")
        logger.info(f"  - Classifier: {type(self.classifier).__name__}")
        logger.info(f"  - Memory: {type(self.memory).__name__}")
        logger.info(f"  - Validator: {type(self.validator).__name__}")

    async def process(
        self,
        query: str,
        history: Optional[List[Dict]] = None,
        **kwargs
    ) -> Dict[str, any]:
        """
        å¤„ç†æŸ¥è¯¢ï¼ˆå®ç° BaseAgentï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            {
                "query": str,
                "answer": str,
                "classification": Dict,
                "decision": Dict,           # æ–°å¢ï¼šAgentå†³ç­–
                "sources": List[Dict],
                "metadata": Dict,
                "quality_check": Dict
            }
        """
        # æ­¥éª¤ 0ï¼šåˆ†ææŸ¥è¯¢æ„å›¾ï¼ˆAgentå†³ç­–ï¼‰
        logger.info(f"ğŸ“‹ [Agent Decision] æ­£åœ¨åˆ†ææŸ¥è¯¢æ„å›¾...")
        decision = await self.analyze_intent(query, history)
        logger.info(f"  â†’ å†³ç­–ç±»å‹: {decision.decision_type} | æ„å›¾: {decision.intent[:30]}")

        # æ­¥éª¤ 1ï¼šåˆ†ç±»é—®æ”¿ç±»å‹
        logger.info(f"ğŸ“‹ [Classifier] æ­£åœ¨åˆ†ç±»é—®æ”¿ç±»å‹...")
        classification = await self.classifier.classify_gov_request(query)
        logger.info(f"  â†’ é—®æ”¿ç±»å‹: {classification['type']} (ç½®ä¿¡åº¦: {classification['confidence']:.2f})")

        # æ­¥éª¤ 2ï¼šæ£€ç´¢ç›¸å…³æ¡ˆä¾‹
        logger.info(f"ğŸ” [Retriever] æ‰§è¡Œæ£€ç´¢...")
        context, results, metadata = self.retriever.retrieve(query)
        logger.info(f"  â†’ æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")

        # æ­¥éª¤ 3ï¼šç”Ÿæˆå›ç­”
        logger.info("ğŸ¤– [Generator] æ­£åœ¨ç”Ÿæˆå›ç­”...")
        answer = await self.generator.generate(
            prompt=query,
            system_message="åŸºäºæ£€ç´¢åˆ°çš„æ¡ˆä¾‹ç”Ÿæˆå‡†ç¡®å›ç­”",
            history=history
        )
        logger.info(f"  â†’ å›ç­”ç”Ÿæˆå®Œæˆ: {answer[:50]}...")

        # æ­¥éª¤ 4ï¼šä¿å­˜åˆ°è®°å¿†
        if history is None:
            self.memory.add_message({"role": "user", "content": query})
            self.memory.add_message({"role": "assistant", "content": answer})
        else:
            # ä½¿ç”¨å¤–éƒ¨å†å²
            pass

        # æ­¥éª¤ 5ï¼šè´¨é‡æ ¡éªŒ
        logger.info("ğŸ” [Validator] æ­£åœ¨æ ¡éªŒå›ç­”è´¨é‡...")
        validation = await self.validator.validate(answer, query, context)

        return {
            "query": query,
            "answer": answer,
            "classification": classification,
            "decision": decision.model_dump(),  # æ–°å¢ï¼šAgentå†³ç­–
            "sources": results[:5],  # æœ€å¤šè¿”å› 5 ä¸ªæ¥æº
            "metadata": metadata,
            "quality_check": validation
        }

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        # å¹¶è¡Œåˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        await asyncio.gather(
            self.classifier.initialize(),
            self.generator.initialize(),
            self.validator.initialize()
        )
        self._initialized = True
        logger.info("âœ… RagAgent åˆå§‹åŒ–å®Œæˆ")

    def get_status(self) -> Dict[str, any]:
        """è·å–çŠ¶æ€"""
        memory_stats = self.memory.get_stats()
        return {
            "name": self.name,
            "initialized": self._initialized,
            "created_at": self.created_at.isoformat(),
            "components": {
                "retriever": type(self.retriever).__name__,
                "generator": type(self.generator).__name__,
                "classifier": type(self.classifier).__name__,
                "memory": type(self.memory).__name__,
                "validator": type(self.validator).__name__,
            },
            "memory_stats": memory_stats
        }

    # ==================== Agent å†³ç­–èƒ½åŠ› ====================

    async def analyze_intent(
        self,
        query: str,
        history: Optional[List[Dict]] = None
    ) -> AgentDecision:
        """
        Agent æ ¸å¿ƒèƒ½åŠ›ï¼šåˆ†ææŸ¥è¯¢æ„å›¾å¹¶ç”Ÿæˆæ£€ç´¢å†³ç­–

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰

        Returns:
            AgentDecision: å†³ç­–ç»“æœ
        """
        # æ„å»ºå†³ç­– Prompt
        prompt_parts = [
            "ä½ æ˜¯ä¸€å RAG Agent å†³ç­–åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶ç»™å‡ºæ£€ç´¢å†³ç­–ã€‚",
            "",
            "# å†³ç­–ä»»åŠ¡ï¼š",
            "1. åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ ¸å¿ƒæ„å›¾",
            "2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢çŸ¥è¯†åº“",
            "3. é€‰æ‹©æœ€ä¼˜æ£€ç´¢ç­–ç•¥",
            "4. è°ƒæ•´æ£€ç´¢å‚æ•°ï¼ˆå¦‚ top_kã€é˜ˆå€¼ï¼‰",
            "5. å¿…è¦æ—¶é‡å†™æŸ¥è¯¢è¯­å¥",
            "",
            "# å†³ç­–è§„åˆ™ï¼š",
            "- direct_answerï¼šé€šç”¨æ”¿åŠ¡å¸¸è¯†ã€æ— éœ€å…·ä½“æ¡ˆä¾‹æ”¯æ’‘çš„é—®é¢˜ï¼ˆå¦‚'å¦‚ä½•åŠç†èº«ä»½è¯'çš„é€šç”¨æµç¨‹ï¼‰",
            "- need_retrievalï¼šéœ€è¦å…·ä½“æ”¿ç­–/æ¡ˆä¾‹æ”¯æ’‘çš„é—®é¢˜ï¼ˆå¦‚'2024å¹´æ³¸å·é›¨éœ²è®¡åˆ’è¡¥è´´æ ‡å‡†'ï¼‰",
            "- multi_retrievalï¼šè·¨éƒ¨é—¨/å¤šæ”¿ç­–çš„å¤æ‚é—®é¢˜ï¼ˆå¦‚'æ³¸å·å°å¾®ä¼ä¸šç¨æ”¶ä¼˜æƒ +ç¤¾ä¿è¡¥è´´'ï¼‰",
            "- cannot_answerï¼šéæ³¸å·å¸‚æ”¿åŠ¡é—®é¢˜/æ— æ„ä¹‰é—®é¢˜/æ•æ„Ÿé—®é¢˜",
            "",
            "# æ£€ç´¢ç­–ç•¥é€‰æ‹©ï¼š",
            "- hybridï¼šé»˜è®¤ç­–ç•¥ï¼Œæ··åˆè¯­ä¹‰+å…³é”®è¯æ£€ç´¢",
            "- keywordï¼šå¼ºå…³é”®è¯ç‰¹å¾çš„é—®é¢˜ï¼ˆå¦‚'2024å¹´æ³¸å·åŒ»ä¿ç¼´è´¹æ ‡å‡†'ï¼‰",
            "- semantic_onlyï¼šè¯­ä¹‰æ¨¡ç³Š/å¤šä¹‰è¯é—®é¢˜ï¼ˆå¦‚'æ³¸å·åˆ›ä¸šæ‰¶æŒæ”¿ç­–'ï¼‰",
            "- cross_deptï¼šè·¨éƒ¨é—¨é—®é¢˜ï¼ˆå¦‚'æ³¸å·ä½æˆ¿è¡¥è´´+å…¬ç§¯é‡‘æ”¿ç­–'ï¼‰",
            "",
            "# è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š",
            "{",
            '    "decision_type": "direct_answer|need_retrieval|multi_retrieval|cannot_answer",',
            '    "retrieval_strategy": "hybrid|keyword|semantic_only|cross_dept",',
            '    "retrieval_params": {"top_k": 5-10, "threshold": 0.5-0.8},',
            '    "query_rewritten": "é‡å†™åçš„æŸ¥è¯¢è¯­å¥ï¼ˆå¯é€‰ï¼‰",',
            '    "intent": "æ ¸å¿ƒæ„å›¾æè¿°",',
            '    "confidence": 0.0-1.0',
            "}",
            "",
            "# æ³¨æ„ï¼š",
            "- retrieval_strategy/cross_dept ä»…åœ¨ decision_type ä¸º need_retrieval/multi_retrieval æ—¶å¿…å¡«",
            "- retrieval_params éœ€æ ¹æ®é—®é¢˜å¤æ‚åº¦è°ƒæ•´ï¼ˆå¤æ‚é—®é¢˜ top_k=8-10ï¼Œç®€å•é—®é¢˜=3-5ï¼‰",
            "- query_rewritten éœ€æ›´ç²¾å‡†è¡¨è¾¾æ ¸å¿ƒæ„å›¾ï¼ˆå¦‚åŸé—®é¢˜'é›¨éœ²è®¡åˆ’å¤šå°‘é’±'â†’'2024å¹´æ³¸å·å¸‚é›¨éœ²è®¡åˆ’è¡¥è´´é‡‘é¢æ ‡å‡†'ï¼‰",
            "",
            "# ç”¨æˆ·æŸ¥è¯¢ï¼š",
            query,
        ]

        # æ·»åŠ å¯¹è¯å†å²
        if history and len(history) > 0:
            prompt_parts.append("\n# å¯¹è¯å†å²ï¼š")
            for turn in history[-3:]:
                role = "ç”¨æˆ·" if turn["role"] == "user" else "åŠ©æ‰‹"
                prompt_parts.append(f"{role}ï¼š{turn['content']}")

        prompt = "\n".join(prompt_parts)

        try:
            # ä½¿ç”¨è½»é‡æ¨¡å‹ç”Ÿæˆå†³ç­–
            light_llm = get_light_llm_service()
            response = Generation.call(
                model=light_llm.get_model_name(),
                prompt=prompt,
                temperature=light_llm.get_config().temperature,
                max_tokens=500,
                top_p=light_llm.get_config().top_p,
                result_format='text'
            )

            if response.status_code == 200:
                decision_str = response.output.text
                # è§£æ JSON å†³ç­–
                decision_data = json.loads(decision_str)
                return AgentDecision(**decision_data)
            else:
                raise Exception(f"å†³ç­–ç”Ÿæˆå¤±è´¥: {response.code} - {response.message}")

        except Exception as e:
            logger.error(f"âŒ Agent å†³ç­–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            # è¿”å›é»˜è®¤å†³ç­–ï¼ˆå…œåº•ï¼‰
            return AgentDecision(
                decision_type="need_retrieval",
                retrieval_strategy="hybrid",
                retrieval_params={"top_k": 5, "threshold": 0.6},
                query_rewritten=query,
                intent=f"æ— æ³•è§£ææ„å›¾ï¼šé€šç”¨æŸ¥è¯¢",
                confidence=0.5
            )


    # ==================== å…¼å®¹æ€§æ–¹æ³• ====================

    async def query(
        self,
        query: str,
        history: Optional[List[Dict]] = None,
        **kwargs
    ) -> Dict[str, any]:
        """
        å…¼å®¹æ—§æ¥å£ï¼šquery() æ–¹æ³•

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            å¤„ç†ç»“æœ
        """
        return await self.process(query, history, **kwargs)


# ==================== å·¥å…·å‡½æ•° ====================

async def query_agentic_rag(
    query: str,
    history: Optional[List[Dict]] = None,
    **kwargs
) -> Dict[str, any]:
    """
    å¿«é€Ÿè°ƒç”¨ Agentic RAG æŸ¥è¯¢

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        å¤„ç†ç»“æœ
    """
    agent = RagAgent()
    return await agent.process(query, history, **kwargs)
