"""
ReAct Agent æ ¸å¿ƒå®ç°
Thought-Action-Observation å¾ªç¯å¼•æ“

ReActèŒƒå¼ï¼š
1. Thought: LLM åˆ†æå½“å‰çŠ¶æ€å¹¶ç”Ÿæˆæ€è€ƒ
2. Action: é€‰æ‹©å¹¶æ‰§è¡Œå·¥å…·
3. Observation: è·å–å·¥å…·æ‰§è¡Œç»“æœ
4. å¾ªç¯ç›´åˆ°ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæˆ–è¾¾åˆ°æœ€å¤§æ­¥æ•°

ä½¿ç”¨è£…é¥°å™¨æ¨¡å¼æ³¨å†Œå·¥å…·ï¼š
    from src.app.agents.tools.registry import ToolRegistry

    @ToolRegistry.register()
    class MyTool(BaseTool):
        name = "my_tool"
        description = "æˆ‘çš„å·¥å…·"

        async def execute(self, **kwargs) -> dict:
            return {"result": "xxx"}

ä½¿ç”¨ ReactAgentï¼š
    from src.app.agents import ReactAgent
    from src.app.agents.tools import ToolRegistry

    tools = {
        "retrieve": ToolRegistry.get_instance("retrieve"),
        "generate": ToolRegistry.get_instance("generate"),
        "classify": ToolRegistry.get_instance("classify"),
        "validate": ToolRegistry.get_instance("validate"),
    }
    agent = ReactAgent(tools, max_steps=5)
    result = await agent.process("2024å¹´æ³¸å·é›¨éœ²è®¡åˆ’è¡¥è´´æ ‡å‡†")
"""

import json
import traceback
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple, Protocol
from pydantic import BaseModel
from src.app.infra.llm.multi_model_service import (
    get_optimizer_llm_service,
    get_heavy_llm_service
)
from src.app.infra.utils.logger import get_logger
from dashscope import Generation

logger = get_logger(__name__)


class BaseTool(Protocol):
    """å·¥å…·åè®® - å®šä¹‰ ReAct å·¥å…·æ¥å£"""

    @property
    def name(self) -> str: ...
    @property
    def description(self) -> str: ...

    async def execute(self, **kwargs) -> Dict[str, Any]: ...


class ReactStep(BaseModel):
    """
    ReAct æ¨ç†æ­¥éª¤è®°å½•

    è®°å½•æ¯ä¸€æ­¥çš„æ€è€ƒã€è¡ŒåŠ¨ã€è§‚å¯Ÿç»“æœ
    """

    step_number: int              # æ­¥éª¤ç¼–å·
    thought: str                  # æ€è€ƒå†…å®¹
    action: str                   # åŠ¨ä½œåç§°
    action_input: Dict[str, Any]  # åŠ¨ä½œå‚æ•°
    observation: str              # è§‚å¯Ÿç»“æœ
    timestamp: datetime           # æ—¶é—´æˆ³

    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

    def __repr__(self):
        return f"Step {self.step_number}: {self.action}"


class ReactAgent:
    """
    ReAct Agent æ ¸å¿ƒç±»

    å®ç° Thought-Action-Observation å¾ªç¯ï¼š
    1. Thought: LLM åˆ†æå½“å‰çŠ¶æ€å¹¶ç”Ÿæˆæ€è€ƒ
    2. Action: é€‰æ‹©å¹¶æ‰§è¡Œå·¥å…·
    3. Observation: è·å–å·¥å…·æ‰§è¡Œç»“æœ
    4. å¾ªç¯ç›´åˆ°ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæˆ–è¾¾åˆ°æœ€å¤§æ­¥æ•°

    ç¤ºä¾‹ï¼š
        from src.app.agents import ReactAgent
        from src.app.agents.tools import ToolRegistry

        tools = {
            "retrieve": ToolRegistry.get_instance("retrieve"),
            "generate": ToolRegistry.get_instance("generate"),
            "classify": ToolRegistry.get_instance("classify"),
            "validate": ToolRegistry.get_instance("validate"),
        }
        agent = ReactAgent(tools, max_steps=5)
        result = await agent.process("2024å¹´æ³¸å·é›¨éœ²è®¡åˆ’è¡¥è´´æ ‡å‡†")
        print(result["answer"])
    """

    def __init__(
        self,
        tools: Dict[str, BaseTool],
        max_steps: int = 5,
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ– ReactAgent

        Args:
            tools: å·¥å…·å­—å…¸ï¼Œé”®ä¸ºå·¥å…·åç§°ï¼Œå€¼ä¸ºå·¥å…·å®ä¾‹
            max_steps: æœ€å¤§æ¨ç†æ­¥æ•°ï¼ˆé»˜è®¤ 5ï¼‰
            verbose: æ˜¯å¦å¼€å¯è¯¦ç»†æ—¥å¿—ï¼ˆé»˜è®¤ Falseï¼‰
        """
        self.tools = tools
        self.max_steps = max_steps
        self.verbose = verbose
        self._initialized = False

        logger.info(
            f"âœ… ReactAgent åˆå§‹åŒ–å®Œæˆ (max_steps={max_steps}, "
            f"tools={list(tools.keys())})"
        )

    async def process(
        self,
        query: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ ReAct æ¨ç†å¾ªç¯

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            {
                "answer": str,              # æœ€ç»ˆç­”æ¡ˆ
                "steps_history": List[Dict],  # æ¨ç†æ­¥éª¤å†å²
                "steps_count": int,           # æ¨ç†æ­¥æ•°
                "sources": List[Dict],        # æ£€ç´¢æ¥æº
                "retrieval_time": float       # æ£€ç´¢è€—æ—¶
            }
        """
        logger.info(f"ğŸš€ [ReactAgent] å¼€å§‹å¤„ç†æŸ¥è¯¢: {query[:50]}...")

        # åˆå§‹åŒ–æ­¥éª¤å†å²
        steps_history: List[ReactStep] = []

        # å¾ªç¯æ‰§è¡Œ Thought-Action-Observation
        final_answer = ""
        sources = []
        retrieval_time = 0.0

        for step_count in range(self.max_steps):
            step_number = step_count + 1

            # ========== Thought: LLM åˆ†æå½“å‰çŠ¶æ€ ==========
            logger.debug(f"ğŸ’­ [Step {step_number}] ç”Ÿæˆæ€è€ƒ...")

            thought, action, action_input = await self._generate_thought_and_action(
                query=query,
                steps_history=steps_history
            )

            logger.debug(f"  â†’ æ€è€ƒ: {thought[:100]}...")
            logger.debug(f"  â†’ åŠ¨ä½œ: {action} | è¾“å…¥: {action_input}")

            # ========== Action: æ‰§è¡Œå·¥å…· ==========
            logger.debug(f"âš™ï¸ [Step {step_number}] æ‰§è¡ŒåŠ¨ä½œ: {action}")

            observation = await self._execute_tool(action, action_input)

            # è®°å½•æ£€ç´¢ç»“æœ
            if action == "retrieve":
                if "results" in action_input and isinstance(action_input["results"], list):
                    sources.extend(action_input["results"])
                if "metadata" in action_input and "retrieval_time" in action_input["metadata"]:
                    retrieval_time = action_input["metadata"]["retrieval_time"]

            # ========== è®°å½•æ­¥éª¤ ==========
            step = ReactStep(
                step_number=step_number,
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation,
                timestamp=datetime.now()
            )
            steps_history.append(step)

            if self.verbose:
                logger.info(f"ğŸ“Š Step {step_number}: {action} â†’ {observation[:50]}...")

            # ========== åˆ¤æ–­æ˜¯å¦ç»“æŸ ==========
            if action == "Final Answer":
                final_answer = action_input.get("answer", observation)
                logger.info(f"âœ… [ReactAgent] ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ (æ­¥æ•°: {step_number})")
                break

        # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä»æœªç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œå¼ºåˆ¶ç”Ÿæˆ
        if not final_answer:
            logger.warning(f"âš ï¸  è¾¾åˆ°æœ€å¤§æ­¥æ•° ({self.max_steps})ï¼Œå¼ºåˆ¶ç”Ÿæˆç­”æ¡ˆ")
            final_answer = await self._generate_final_answer(query, steps_history)

        # åºåˆ—åŒ–æ­¥éª¤å†å²
        serialized_steps = [step.model_dump() for step in steps_history]

        return {
            "answer": final_answer,
            "steps_history": serialized_steps,
            "steps_count": len(steps_history),
            "sources": sources,
            "retrieval_time": retrieval_time
        }

    async def _generate_thought_and_action(
        self,
        query: str,
        steps_history: List[ReactStep]
    ) -> Tuple[str, str, Dict[str, Any]]:
        """
        ç”Ÿæˆæ€è€ƒå’ŒåŠ¨ä½œ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            steps_history: æ­¥éª¤å†å²

        Returns:
            (thought, action, action_input)
        """
        # æ„å»º ReAct æç¤º
        prompt = self._build_react_prompt(query, steps_history)

        try:
            # ä½¿ç”¨ä¼˜åŒ–æ¨¡å‹ç”Ÿæˆæ€è€ƒå’ŒåŠ¨ä½œ
            optimizer_llm = get_optimizer_llm_service()
            response = Generation.call(
                model=optimizer_llm.get_model_name(),
                prompt=prompt,
                temperature=optimizer_llm.get_config().temperature,
                max_tokens=500,
                top_p=optimizer_llm.get_config().top_p,
                result_format='text'
            )

            if response.status_code == 200:
                response_text = response.output.text
                thought, action, action_input = self._parse_react_response(response_text)
                return thought, action, action_input
            else:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ€è€ƒå’ŒåŠ¨ä½œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            # è¿”å›é»˜è®¤åŠ¨ä½œï¼ˆæ£€ç´¢ï¼‰
            return (
                f"éœ€è¦æ£€ç´¢ç›¸å…³ä¿¡æ¯æ¥å›ç­”é—®é¢˜: {query}",
                "retrieve",
                {"query": query, "top_k": 5}
            )

    def _build_react_prompt(
        self,
        query: str,
        steps: List[ReactStep]
    ) -> str:
        """
        æ„å»º ReAct æç¤ºæ¨¡æ¿

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            steps: æ­¥éª¤å†å²

        Returns:
            å®Œæ•´çš„æç¤ºæ–‡æœ¬
        """
        parts = []

        # ä»»åŠ¡æè¿°
        parts.append("# ä»»åŠ¡æè¿°")
        parts.append("ä½ æ˜¯ä¸€ä¸ª ReAct Agentï¼Œéœ€è¦é€šè¿‡æ€è€ƒ(Thought)ã€è¡ŒåŠ¨(Action)ã€è§‚å¯Ÿ(Observation)çš„å¾ªç¯æ¥å›ç­”é—®é¢˜ã€‚")
        parts.append("")
        parts.append("# å¯ç”¨å·¥å…·")
        for tool_name, tool in self.tools.items():
            parts.append(f"- {tool_name}: {tool.description}")
        parts.append("")
        parts.append("# è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼‰")
        parts.append("Thought: [åŸºäºå½“å‰çŠ¶æ€çš„æ€è€ƒ]")
        parts.append("Action: [å·¥å…·åç§°æˆ– 'Final Answer']")
        parts.append("Action Input: {\"key\": \"value\"}")
        parts.append("")
        parts.append("# æ³¨æ„äº‹é¡¹")
        parts.append("- Action å¿…é¡»æ˜¯å¯ç”¨å·¥å…·ä¹‹ä¸€ï¼Œæˆ– 'Final Answer'")
        parts.append("- Action Input å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON å¯¹è±¡")
        parts.append("- Final Answer ç”¨äºç”Ÿæˆæœ€ç»ˆå›ç­”")
        parts.append("")

        # å¯¹è¯å†å²
        if steps:
            parts.append("# æ¨ç†å†å²")
            for step in steps:
                parts.append(f"Thought {step.step_number}: {step.thought}")
                parts.append(f"Action {step.step_number}: {step.action}")
                parts.append(f"Action Input {step.step_number}: {json.dumps(step.action_input, ensure_ascii=False)}")
                observation_preview = step.observation[:200] if len(step.observation) > 200 else step.observation
                parts.append(f"Observation {step.step_number}: {observation_preview}")
                parts.append("")
        else:
            parts.append("# æ¨ç†å†å²")
            parts.append("æ— ")
            parts.append("")

        # å½“å‰æŸ¥è¯¢
        parts.append("# å½“å‰æŸ¥è¯¢")
        parts.append(query)
        parts.append("")

        # å½“å‰æ­¥éª¤
        parts.append("# å½“å‰æ­¥éª¤")
        parts.append("Thought:")

        return "\n".join(parts)

    def _parse_react_response(
        self,
        response: str
    ) -> Tuple[str, str, Dict[str, Any]]:
        """
        è§£æ LLM å“åº”ä¸º Thoughtã€Actionã€Action Input

        Args:
            response: LLM å“åº”æ–‡æœ¬

        Returns:
            (thought, action, action_input)
        """
        thought = ""
        action = "Final Answer"
        action_input = {}

        lines = response.strip().split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("Thought:") or line.startswith("Thoughtï¼š"):
                thought = line.split(":", 1)[1].strip() if ":" in line else line.split("ï¼š", 1)[1].strip()
            elif line.startswith("Action:") or line.startswith("Actionï¼š"):
                action = line.split(":", 1)[1].strip() if ":" in line else line.split("ï¼š", 1)[1].strip()
            elif line.startswith("Action Input:") or line.startswith("Action Inputï¼š"):
                try:
                    input_str = line.split(":", 1)[1].strip() if ":" in line else line.split("ï¼š", 1)[1].strip()
                    action_input = json.loads(input_str)
                except json.JSONDecodeError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥
                    action_input = {"query": response}

        # å¦‚æœæ²¡æœ‰æå–åˆ°æ€è€ƒï¼Œä½¿ç”¨å“åº”ä½œä¸ºæ€è€ƒ
        if not thought:
            thought = "åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶é€‰æ‹©åˆé€‚çš„å·¥å…·"

        # éªŒè¯å·¥å…·åç§°
        if action != "Final Answer" and action not in self.tools:
            logger.warning(f"âš ï¸  æœªçŸ¥å·¥å…·: {action}ï¼Œä½¿ç”¨é»˜è®¤å·¥å…· 'retrieve'")
            action = "retrieve"
            action_input = {"query": response}

        return thought, action, action_input

    async def _execute_tool(
        self,
        action: str,
        action_input: Dict[str, Any]
    ) -> str:
        """
        æ‰§è¡Œå·¥å…·å¹¶æ ¼å¼åŒ–ç»“æœ

        Args:
            action: åŠ¨ä½œåç§°
            action_input: åŠ¨ä½œå‚æ•°

        Returns:
            è§‚å¯Ÿç»“æœï¼ˆæ ¼å¼åŒ–ä¸ºæ–‡æœ¬ï¼‰
        """
        if action == "Final Answer":
            answer = action_input.get("answer", "")
            return answer

        if action not in self.tools:
            return f"é”™è¯¯ï¼šæœªçŸ¥å·¥å…· {action}"

        try:
            # æ‰§è¡Œå·¥å…·
            tool = self.tools[action]

            # ç‰¹æ®Šå¤„ç†ï¼šGenerationTool éœ€è¦ prompt å‚æ•°
            if action == "generate":
                if "prompt" not in action_input:
                    if "query" in action_input:
                        action_input["prompt"] = action_input["query"]
                    elif "answer" in action_input:
                        action_input["prompt"] = action_input["answer"]
                    else:
                        action_input["prompt"] = ""

            result = await tool.execute(**action_input)

            # æ ¼å¼åŒ–è§‚å¯Ÿç»“æœ
            observation = self._format_observation(result)
            return observation

        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return f"é”™è¯¯ï¼š{str(e)}"

    def _format_observation(self, result: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœä¸ºè‡ªç„¶è¯­è¨€æè¿°

        Args:
            result: å·¥å…·æ‰§è¡Œç»“æœ

        Returns:
            æ ¼å¼åŒ–åçš„è§‚å¯Ÿæ–‡æœ¬
        """
        if "answer" in result:
            return result["answer"]

        if "results" in result:
            results = result["results"]
            if isinstance(results, list) and len(results) > 0:
                lines = ["æ£€ç´¢åˆ°ä»¥ä¸‹ç›¸å…³æ¡ˆä¾‹ï¼š"]
                for idx, item in enumerate(results[:5], 1):
                    title = item.get("title", "æ— æ ‡é¢˜")
                    dept = item.get("department", "æœªçŸ¥éƒ¨é—¨")
                    lines.append(f"{idx}. {title} ({dept})")
                return "\n".join(lines)

        if "type" in result:
            type_ = result.get("type", "æœªçŸ¥")
            confidence = result.get("confidence", 0.0)
            return f"é—®æ”¿ç±»å‹: {type_}, ç½®ä¿¡åº¦: {confidence:.2f}"

        if "overall_score" in result:
            score = result.get("overall_score", 0.0)
            passed = result.get("passed", False)
            return f"è´¨é‡è¯„åˆ†: {score:.2f}, é€šè¿‡: {passed}"

        # é»˜è®¤æ ¼å¼åŒ–
        return json.dumps(result, ensure_ascii=False)

    async def _generate_final_answer(
        self,
        query: str,
        steps_history: List[ReactStep]
    ) -> str:
        """
        ä½¿ç”¨ä¸»æ¨¡å‹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            steps_history: æ­¥éª¤å†å²

        Returns:
            æœ€ç»ˆç­”æ¡ˆæ–‡æœ¬
        """
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for step in steps_history:
            if step.action == "retrieve" and "results" in step.action_input:
                results = step.action_input["results"]
                for item in results[:3]:
                    title = item.get("title", "")
                    content = item.get("content", "")
                    context_parts.append(f"{title}: {content}")

        context = "\n\n".join(context_parts)

        # ä½¿ç”¨ä¸»æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        try:
            heavy_llm = get_heavy_llm_service()
            prompt = f"""
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

è¯·ç»™å‡ºå‡†ç¡®ã€å®Œæ•´çš„å›ç­”ã€‚
"""

            response = Generation.call(
                model=heavy_llm.get_model_name(),
                prompt=prompt,
                temperature=heavy_llm.get_config().temperature,
                max_tokens=heavy_llm.get_config().max_tokens,
                top_p=heavy_llm.get_config().top_p,
                result_format='text'
            )

            if response.status_code == 200:
                return response.output.text
            else:
                return "æŠ±æ­‰ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯ã€‚"

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return "æŠ±æ­‰ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯ã€‚"

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰å·¥å…·ï¼ˆé¢„çƒ­ï¼‰"""
        logger.info("â³ [ReactAgent] åˆå§‹åŒ–å·¥å…·...")
        for tool_name, tool in self.tools.items():
            if hasattr(tool, 'initialize') and callable(tool.initialize):
                try:
                    await tool.initialize()
                    logger.info(f"  âœ… {tool_name} å·²é¢„çƒ­")
                except Exception as e:
                    logger.warning(f"  âš ï¸ {tool_name} é¢„çƒ­å¤±è´¥: {e}")
        self._initialized = True
        logger.info("âœ… [ReactAgent] åˆå§‹åŒ–å®Œæˆ")

    def get_status(self) -> Dict[str, Any]:
        """è·å– Agent çŠ¶æ€"""
        return {
            "initialized": self._initialized,
            "max_steps": self.max_steps,
            "tools": list(self.tools.keys()),
            "verbose": self.verbose
        }
