"""
å¤šæ¨¡å‹ LLM æœåŠ¡ç®¡ç†å™¨
é‡‡ç”¨é…ç½®é©±åŠ¨çš„æ¨¡å‹æ³¨å†Œè¡¨æ¨¡å¼ï¼Œæ”¯æŒçµæ´»çš„å¤šæ¨¡å‹é…ç½®

æ¶æ„è®¾è®¡ï¼š
1. æ¨¡å‹é…ç½®ï¼ˆModelConfigï¼‰ï¼šå®šä¹‰æ¯ä¸ªæ¨¡å‹çš„ç‹¬ç«‹é…ç½®ï¼ˆapi_keyã€å‚æ•°ç­‰ï¼‰
2. LLM æœåŠ¡ï¼ˆLLMServiceï¼‰ï¼šå°è£…å•ä¸ªæ¨¡å‹çš„è°ƒç”¨é€»è¾‘
3. æ¨¡å‹æ³¨å†Œè¡¨ï¼ˆModelRegistryï¼‰ï¼šå•ä¾‹æ¨¡å¼ï¼Œé›†ä¸­ç®¡ç†æ‰€æœ‰æ¨¡å‹å®ä¾‹
4. ä¾¿æ·è®¿é—®ï¼šé€šè¿‡é¢„å®šä¹‰å‡½æ•°æˆ–ç”¨é€”æšä¸¾è·å–æœåŠ¡

ä½¿ç”¨æ–¹å¼ï¼š
    # æ–¹å¼1ï¼šç›´æ¥è·å–ï¼ˆæ¨èï¼‰
    llm = get_heavy_llm_service()

    # æ–¹å¼2ï¼šé€šè¿‡ç”¨é€”è·å–ï¼ˆæ›´è¯­ä¹‰åŒ–ï¼‰
    llm = get_llm_service_by_purpose(ModelPurpose.GENERATION)

    # è·å–æ¨¡å‹é…ç½®
    config = llm.get_config()
    temperature = config.temperature
"""

import dashscope
from typing import Dict, Optional
from enum import Enum
from src.config.setting import settings
from src.app.infra.utils.logger import get_logger

logger = get_logger(__name__)


class ModelPurpose(Enum):
    """æ¨¡å‹ç”¨é€”æšä¸¾"""
    GENERATION = "generation"      # ä¸»æ¨¡å‹ï¼šç”Ÿæˆå¤æ‚å›ç­”
    CLASSIFICATION = "classification"  # è½»é‡æ¨¡å‹ï¼šåˆ†ç±»ã€æ ¡éªŒ
    OPTIMIZATION = "optimization"  # ä¼˜åŒ–æ¨¡å‹ï¼šPromptä¼˜åŒ–ã€Agentå†³ç­–


class ModelConfig:
    """å•ä¸ªæ¨¡å‹çš„é…ç½®"""

    def __init__(
        self,
        name: str,
        api_key: str,
        purpose: ModelPurpose,
        temperature: float = 0.1,
        max_tokens: int = 2000,
        top_p: float = 0.9,
    ):
        self.name = name
        self.api_key = api_key
        self.purpose = purpose
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.top_p = top_p


class LLMService:
    """å•ä¸ª LLM æœåŠ¡å®ä¾‹"""

    def __init__(self, config: ModelConfig):
        self.config = config
        self.model_name = config.name

        # é…ç½® API å¯†é’¥
        dashscope.api_key = config.api_key

        logger.info(
            f"ğŸ”„ åˆå§‹åŒ– {config.purpose.value} LLM æœåŠ¡: {config.name}"
        )

    def get_model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        return self.model_name

    def get_config(self) -> ModelConfig:
        """è·å–æ¨¡å‹é…ç½®"""
        return self.config


class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œè¡¨ - å•ä¾‹æ¨¡å¼"""

    _instance: Optional["ModelRegistry"] = None
    _services: Dict[str, LLMService] = {}

    def __new__(cls):
        if not cls._instance:
            cls._instance = super(ModelRegistry, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if getattr(self, "_initialized", False):
            return

        # ä»é…ç½®ä¸­æ³¨å†Œæ‰€æœ‰æ¨¡å‹
        self._register_models_from_config()
        self._initialized = True
        logger.info("âœ… æ¨¡å‹æ³¨å†Œè¡¨åˆå§‹åŒ–å®Œæˆ")

    def _register_models_from_config(self):
        """ä» settings é…ç½®ä¸­æ³¨å†Œæ¨¡å‹"""

        # æ³¨å†Œä¸»æ¨¡å‹ï¼ˆç”Ÿæˆï¼‰
        heavy_config = ModelConfig(
            name=settings.llm.heavy_model_name,
            api_key=settings.llm.api_key,  # å¯ä»¥æ‰©å±•ä¸º settings.llm.heavy_api_key
            purpose=ModelPurpose.GENERATION,
            temperature=settings.llm.temperature,
            max_tokens=settings.llm.max_tokens,
            top_p=settings.llm.top_p,
        )
        self._register_service("heavy", LLMService(heavy_config))

        # æ³¨å†Œè½»é‡æ¨¡å‹ï¼ˆåˆ†ç±»ï¼‰
        light_config = ModelConfig(
            name=settings.llm.light_model_name,
            api_key=settings.llm.api_key,  # å¯ä»¥æ‰©å±•ä¸º settings.llm.light_api_key
            purpose=ModelPurpose.CLASSIFICATION,
            temperature=0.1,  # åˆ†ç±»ä»»åŠ¡ä½¿ç”¨æ›´ä½çš„ temperature
            max_tokens=500,   # åˆ†ç±»ä»»åŠ¡ token é™åˆ¶æ›´ä½
            top_p=0.9,
        )
        self._register_service("light", LLMService(light_config))

        # æ³¨å†Œä¼˜åŒ–æ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸è½»é‡æ¨¡å‹å…±ç”¨ï¼‰
        if hasattr(settings.llm, "optimizer_model_name"):
            optimizer_config = ModelConfig(
                name=settings.llm.optimizer_model_name,
                api_key=settings.llm.api_key,
                purpose=ModelPurpose.OPTIMIZATION,
                temperature=0.3,
                max_tokens=1000,
                top_p=0.9,
            )
            self._register_service("optimizer", LLMService(optimizer_config))
        else:
            # ä¸è½»é‡æ¨¡å‹å…±ç”¨
            self._services["optimizer"] = self._services["light"]
            logger.info("  â†’ ä¼˜åŒ–æ¨¡å‹ä¸è½»é‡æ¨¡å‹å…±ç”¨")

    def _register_service(self, key: str, service: LLMService):
        """æ³¨å†ŒæœåŠ¡å®ä¾‹"""
        self._services[key] = service
        logger.info(
            f"  â†’ å·²æ³¨å†Œ: {key} ({service.get_model_name()}, "
            f"ç”¨é€”: {service.get_config().purpose.value})"
        )

    def get_service(self, key: str) -> LLMService:
        """é€šè¿‡é”®åè·å–æœåŠ¡"""
        if key not in self._services:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹æœåŠ¡: {key}")
        return self._services[key]

    def get_by_purpose(self, purpose: ModelPurpose) -> LLMService:
        """é€šè¿‡ç”¨é€”è·å–æœåŠ¡"""
        # æ˜ å°„ç”¨é€”åˆ°æœåŠ¡é”®
        purpose_map = {
            ModelPurpose.GENERATION: "heavy",
            ModelPurpose.CLASSIFICATION: "light",
            ModelPurpose.OPTIMIZATION: "optimizer",
        }
        key = purpose_map.get(purpose)
        if not key or key not in self._services:
            raise ValueError(f"æœªæ‰¾åˆ°ç”¨é€”ä¸º {purpose.value} çš„æ¨¡å‹æœåŠ¡")
        return self._services[key]


# ==================== å…¨å±€æ³¨å†Œè¡¨å®ä¾‹ ====================

_registry = ModelRegistry()


# ==================== å·¥å…·å‡½æ•° ====================

def get_heavy_llm_service() -> LLMService:
    """
    è·å–ä¸» LLM æœåŠ¡ï¼ˆç”Ÿæˆå¤æ‚å›ç­”ï¼‰

    ä½¿ç”¨åœºæ™¯ï¼š
    - LLMGeneratorï¼šç”Ÿæˆæœ€ç»ˆå›ç­”
    - å¤æ‚çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡
    """
    return _registry.get_service("heavy")


def get_light_llm_service() -> LLMService:
    """
    è·å–è½»é‡ LLM æœåŠ¡ï¼ˆåˆ†ç±»/æ ¡éªŒç­‰ç®€å•ä»»åŠ¡ï¼‰

    ä½¿ç”¨åœºæ™¯ï¼š
    - GovClassifierï¼šé—®æ”¿åˆ†ç±»
    - å›ç­”è´¨é‡æ ¡éªŒ
    - ç®€å•çš„æ–‡æœ¬åˆ†æä»»åŠ¡
    """
    return _registry.get_service("light")


def get_optimizer_llm_service() -> LLMService:
    """
    è·å–ä¼˜åŒ– LLM æœåŠ¡ï¼ˆAgent å†³ç­–ã€Prompt ä¼˜åŒ–ï¼‰

    ä½¿ç”¨åœºæ™¯ï¼š
    - Agent æ„å›¾åˆ†æ
    - Prompt é‡å†™
    - ä¸­ç­‰å¤æ‚åº¦çš„åˆ†æä»»åŠ¡
    """
    return _registry.get_service("optimizer")


def get_llm_service(purpose: ModelPurpose) -> LLMService:
    """
    æ ¹æ®ç”¨é€”è·å– LLM æœåŠ¡

    Args:
        purpose: æ¨¡å‹ç”¨é€”æšä¸¾

    Returns:
        LLMService: å¯¹åº”çš„ LLM æœåŠ¡å®ä¾‹
    """
    return _registry.get_by_purpose(purpose)
