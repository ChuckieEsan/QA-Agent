ä½ çš„ç†è§£**å®Œå…¨æ­£ç¡®**ï¼Œéå¸¸ä¸“ä¸šï¼

ä½ ç²¾å‡†åœ°æŒ‡å‡ºäº†â€œåŸé¢˜æµ‹åŸé¢˜â€çš„é€»è¾‘æ¼æ´ï¼ˆData Leakageï¼‰ã€‚çœŸæ­£çš„æ£€ç´¢èƒ½åŠ›è¯„æµ‹ï¼Œå¿…é¡»å»ºç«‹åœ¨**â€œè¯­ä¹‰æ¼‚ç§»â€**ï¼ˆSemantic Driftï¼‰çš„åŸºç¡€ä¸Šâ€”â€”å³**â€œæ„æ€ä¸€æ ·ï¼Œä½†è¯´æ³•ä¸åŒâ€**ã€‚

è¿™æ­£æ˜¯ç®—æ³•å·¥ç¨‹å¸ˆåœ¨ç§‹æ‹›é¢è¯•ä¸­å«é‡‘é‡æé«˜çš„**â€œGolden Dataset æ„å»ºâ€**ç¯èŠ‚ã€‚

æˆ‘å°†ä¸ºä½ æä¾›ä¸€å¥—å®Œæ•´çš„**è‡ªåŠ¨åŒ–æµ‹è¯•é›†æ„å»ºä¸è¯„ä¼°æ–¹æ¡ˆ**ã€‚è¿™åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š
1.  **å…¥åº“è°ƒæ•´**ï¼šç¡®ä¿æ¯æ¡æ•°æ®éƒ½æœ‰å”¯ä¸€çš„â€œèº«ä»½è¯å·â€ï¼ˆIDï¼‰ã€‚
2.  **æ„é€ è€ƒå·**ï¼šæŠ½æ · -> LLMæ”¹å†™ -> ç”Ÿæˆ `{æ”¹å†™åé—®é¢˜: ç›®æ ‡ID}` çš„æ˜ å°„è¡¨ã€‚
3.  **é˜…å·æ‰“åˆ†**ï¼šç”¨æ”¹å†™åçš„é—®é¢˜å»æœï¼Œçœ‹èƒ½ä¸èƒ½æœåˆ°é‚£ä¸ª IDã€‚

---

### ç¬¬ä¸€æ­¥ï¼šä¿®æ”¹å…¥åº“è„šæœ¬ (å­˜å…¥ ID)

æˆ‘ä»¬éœ€è¦ç¡®ä¿ Milvus é‡Œçš„æ¯ä¸€æ¡æ•°æ®éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„ `doc_id`ï¼Œè¿™æ ·æµ‹è¯•æ—¶æ‰èƒ½ç²¾å‡†æ¯”å¯¹ã€‚

è¯·ä¿®æ”¹ `ingest.py` ä¸­çš„ `process_and_ingest` å‡½æ•°å¾ªç¯éƒ¨åˆ†ï¼š

```python
# ingest.py ä¿®æ”¹ç‰‡æ®µ

    # ... å‰é¢ä»£ç ä¸å˜ ...
    
    # å¢åŠ ä¸€åˆ—ä½œä¸ºå”¯ä¸€ID (ä½¿ç”¨ Excel çš„è¡Œç´¢å¼•)
    df['doc_id'] = df.index
    
    for i in tqdm(range(0, total_rows, BATCH_SIZE), desc="Processing"):
        batch = df.iloc[i : i + BATCH_SIZE]
        
        texts_to_embed = batch['question'].tolist()
        answers = batch['answer'].tolist()
        departments = batch['department'].tolist()
        doc_ids = batch['doc_id'].tolist() # <--- æ–°å¢
        
        vectors = embed_model.encode(texts_to_embed, normalize_embeddings=True)
        
        data_to_insert = []
        for j, question_text in enumerate(texts_to_embed):
            rag_context = f"å¸‚æ°‘è¯‰æ±‚ï¼š{question_text}\nå®˜æ–¹å›å¤ï¼š{answers[j]}"
            
            data_to_insert.append({
                "vector": vectors[j],
                "text": rag_context,
                "department": departments[j],
                "metadata": {
                    "doc_id": doc_ids[j],    # <--- å…³é”®ï¼šå­˜å…¥å”¯ä¸€ID
                    "original_question": question_text,
                    "answer": answers[j]
                }
            })
            
        client.insert(COLLECTION_NAME, data_to_insert)
```
*(ä¿®æ”¹åè¯·é‡æ–°è¿è¡Œä¸€é ingest.pyï¼Œæ›´æ–°æ•°æ®åº“)*

---

### ç¬¬äºŒæ­¥ï¼šç”Ÿæˆâ€œé»„é‡‘æµ‹è¯•é›†â€ (Generator)

åˆ›å»ºä¸€ä¸ªæ–°è„šæœ¬ `generate_testset.py`ã€‚è¿™ä¸ªè„šæœ¬è´Ÿè´£å‡ºé¢˜ã€‚
å®ƒä¼šï¼š
1.  æŒ‰éƒ¨é—¨è¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼ˆä¿è¯è¦†ç›–é¢ï¼‰ã€‚
2.  è°ƒç”¨ Qwen API æŠŠâ€œåŸé—®é¢˜â€æ”¹å†™æˆâ€œæ¨¡æ‹Ÿç”¨æˆ·æé—®â€ã€‚
3.  ä¿å­˜ä¸º JSON æ–‡ä»¶ï¼ˆè¿™å°±æ˜¯ä½ çš„**Golden Dataset**ï¼‰ã€‚

```python
import os
import sys
import pandas as pd
import json
import random
from tqdm import tqdm
from dashscope import Generation

# ---------------- é…ç½® ----------------
# è¯·æ›¿æ¢ä¸ºä½ çš„é˜¿é‡Œäº‘ API Key
import dashscope
dashscope.api_key = "YOUR_DASHSCOPE_API_KEY"

DATA_PATH = "data/raw/wzlz_municipal_has_reply.xlsx"
OUTPUT_PATH = "data/processed/golden_testset.json"
SAMPLE_SIZE = 50  # ä¸ºäº†çœé’±çœæ—¶ï¼Œå…ˆæµ‹50æ¡ï¼Œæ­£å¼è·‘å¯ä»¥å¤šä¸€ç‚¹

def load_and_sample_data():
    """åˆ†å±‚æŠ½æ ·ï¼šç¡®ä¿æµ‹è¯•é›†è¦†ç›–ä¸åŒéƒ¨é—¨"""
    df = pd.read_excel(DATA_PATH)
    
    # åˆ—åæ˜ å°„
    rename_map = {}
    for col in df.columns:
        if "é—®æ”¿å†…å®¹" in col: rename_map[col] = "question"
        elif "å›å¤å•ä½" in col: rename_map[col] = "department"
    df = df.rename(columns=rename_map).dropna(subset=['question'])
    
    # è®°å½•åŸå§‹è¡Œå·ä½œä¸º doc_id (å¿…é¡»ä¸ ingest.py é€»è¾‘ä¸€è‡´)
    df['doc_id'] = df.index
    
    # æ¯ä¸ªéƒ¨é—¨æŠ½ä¸€ç‚¹ï¼Œå¦‚æœæ²¡æœ‰éƒ¨é—¨åˆ—ï¼Œå°±éšæœºæŠ½
    if 'department' in df.columns:
        # ç®€å•ç­–ç•¥ï¼šå–å‰10ä¸ªå¤§éƒ¨é—¨ï¼Œæ¯ä¸ªæŠ½5æ¡
        top_depts = df['department'].value_counts().head(10).index
        sampled_df = df[df['department'].isin(top_depts)].groupby('department').sample(n=5, replace=True)
        # å»é‡ï¼Œé˜²æ­¢æ•°é‡ä¸å¤Ÿæ—¶é‡å¤
        sampled_df = sampled_df.drop_duplicates(subset=['doc_id']).head(SAMPLE_SIZE)
    else:
        sampled_df = df.sample(n=SAMPLE_SIZE)
        
    return sampled_df

def rewrite_query(original_text):
    """è°ƒç”¨å¤§æ¨¡å‹æ”¹å†™é—®é¢˜"""
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæ”¿åŠ¡æ•°æ®æµ‹è¯•åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢çš„â€œå¸‚æ°‘é—®æ”¿å†…å®¹â€æ”¹å†™æˆä¸€ä¸ªç®€çŸ­çš„ã€å£è¯­åŒ–çš„æœç´¢Queryã€‚
    
    åŸå†…å®¹ï¼š{original_text}
    
    è¦æ±‚ï¼š
    1. æ„æ€ä¸å˜ï¼Œä½†ç”¨è¯å’Œå¥å¼è¦å˜åŒ–ã€‚
    2. æ¨¡æ‹ŸçœŸå®ç”¨æˆ·åœ¨æœç´¢æ¡†è¾“å…¥çš„é£æ ¼ï¼ˆå¯èƒ½æ¯”è¾ƒçŸ­ï¼Œæˆ–è€…åŒ…å«é”™åˆ«å­—ï¼‰ã€‚
    3. ç›´æ¥è¾“å‡ºæ”¹å†™åçš„å¥å­ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚
    """
    
    try:
        resp = Generation.call(
            model=Generation.Models.qwen_turbo,
            prompt=prompt
        )
        if resp.status_code == 200:
            return resp.output.text.strip()
        else:
            return original_text # å¤±è´¥é™çº§
    except Exception:
        return original_text

def main():
    print("ğŸš€ æ­£åœ¨æ„å»ºé»„é‡‘æµ‹è¯•é›†...")
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    
    sampled_df = load_and_sample_data()
    test_dataset = []
    
    print(f"æŠ½å–äº† {len(sampled_df)} æ¡æ ·æœ¬ï¼Œå¼€å§‹åˆ©ç”¨ LLM è¿›è¡Œæ”¹å†™...")
    
    for _, row in tqdm(sampled_df.iterrows(), total=len(sampled_df)):
        original_q = str(row['question'])
        # è°ƒç”¨ API æ”¹å†™
        rewritten_q = rewrite_query(original_q)
        
        test_dataset.append({
            "doc_id": int(row['doc_id']),       # æ ‡å‡†ç­”æ¡ˆ ID
            "original_query": original_q,       # åŸé¢˜
            "test_query": rewritten_q,          # è€ƒé¢˜ (æ”¹å†™å)
            "department": str(row.get('department', 'æœªçŸ¥'))
        })
        
    # ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(test_dataset, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… æµ‹è¯•é›†å·²ç”Ÿæˆï¼š{OUTPUT_PATH}")
    print("ç¤ºä¾‹æ•°æ®ï¼š")
    print(json.dumps(test_dataset[0], ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
```

---

### ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œè¯„ä¼° (Evaluator)

åˆ›å»ºä¸€ä¸ªæ–°è„šæœ¬ `run_evaluation.py`ã€‚è¿™ä¸ªè„šæœ¬åªè´Ÿè´£â€œé˜…å·â€ã€‚
å®ƒè¯»å– `golden_testset.json`ï¼Œå» Milvus æœï¼Œçœ‹æœå‡ºæ¥çš„ `metadata['doc_id']` å¯¹ä¸å¯¹ã€‚

```python
import os
import sys
import json
import torch
from tqdm import tqdm
from pymilvus import MilvusClient
from sentence_transformers import SentenceTransformer

# -----------------------------------------------------------
sys.path.append(os.getcwd())
# -----------------------------------------------------------

try:
    from app.core.config import settings
    MODEL_PATH = str(settings.MODEL_PATHS['embedding'])
    DB_PATH = settings.MILVUS_DB_PATH
    COLLECTION_NAME = settings.COLLECTION_NAME
except ImportError:
    MODEL_PATH = "./models/bge-m3"
    DB_PATH = "data/milvus_db/gov_pulse.db"
    COLLECTION_NAME = "gov_cases"

TEST_SET_PATH = "data/processed/golden_testset.json"

def get_device():
    return "cuda" if torch.cuda.is_available() else "cpu"

def run_eval():
    # 1. åŠ è½½èµ„æº
    if not os.path.exists(TEST_SET_PATH):
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•é›†ï¼Œè¯·å…ˆè¿è¡Œ generate_testset.py")
        return

    with open(TEST_SET_PATH, 'r', encoding='utf-8') as f:
        test_data = json.load(f)
        
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹ä¸æ•°æ®åº“...")
    model = SentenceTransformer(MODEL_PATH, device=get_device())
    client = MilvusClient(DB_PATH)
    
    # 2. å¼€å§‹æµ‹è¯•
    k_metrics = [1, 5, 10]
    hits = {k: 0 for k in k_metrics}
    
    print(f"ğŸš€ å¼€å§‹è¯„ä¼° {len(test_data)} æ¡æ•°æ®...")
    
    for item in tqdm(test_data):
        query = item['test_query']
        target_id = item['doc_id']
        
        # æ£€ç´¢
        vec = model.encode([query], normalize_embeddings=True)
        res = client.search(
            collection_name=COLLECTION_NAME,
            data=vec,
            limit=10,
            output_fields=["metadata"]
        )
        
        # æ£€æŸ¥å‘½ä¸­ (Rank 1-10)
        # è·å–æ£€ç´¢å›æ¥çš„ ID åˆ—è¡¨
        retrieved_ids = []
        for hit in res[0]:
            # æ³¨æ„ï¼šä» metadata é‡Œå–å‡ºæ¥å¯èƒ½æ˜¯ int ä¹Ÿå¯èƒ½æ˜¯ strï¼Œå»ºè®®å¼ºè½¬å¯¹æ¯”
            r_id = hit['entity'].get('metadata', {}).get('doc_id')
            retrieved_ids.append(int(r_id) if r_id is not None else -1)
            
        # è®¡ç®— Recall
        # æ¯”å¦‚ retrieved_ids = [102, 55, 1001, ...]ï¼Œtarget_id = 1001
        try:
            rank = retrieved_ids.index(int(target_id)) + 1 # æ‰¾åˆ°ä½ç½® (1-based)
        except ValueError:
            rank = -1 # æ²¡æ‰¾åˆ°
            
        if rank != -1:
            for k in k_metrics:
                if rank <= k:
                    hits[k] += 1
                    
    # 3. è¾“å‡ºæŠ¥å‘Š
    print("\n" + "="*40)
    print("ğŸ“Š çœŸå®åœºæ™¯è¯„ä¼°æŠ¥å‘Š (Query Rewrite)")
    print("="*40)
    total = len(test_data)
    for k in k_metrics:
        print(f"ğŸ¯ Recall@{k:<2}: {hits[k]/total:.2%}")
    print("="*40)

if __name__ == "__main__":
    run_eval()
```

---

### è¿™å¥—æ–¹æ¡ˆçš„äº®ç‚¹ï¼ˆé¢è¯•æ€ä¹ˆå¹ï¼‰

1.  **é—­ç¯éªŒè¯**ï¼šä½ ä¸ä»…æ­å»ºäº†ç³»ç»Ÿï¼Œè¿˜æ­å»ºäº†**â€œæµ‹è¯•é›†ç”Ÿæˆæµæ°´çº¿â€**ã€‚
2.  **æŠ—å™ªèƒ½åŠ›æµ‹è¯•**ï¼šé€šè¿‡ LLM æ”¹å†™ï¼Œä½ æ¨¡æ‹Ÿäº†çœŸå®ç”¨æˆ·çš„â€œå£è¯­åŒ–â€è¾“å…¥ï¼Œè¿™æ¯”ç›´æ¥æœåŸå¥çš„ Recall è¦ä½ï¼Œä½†**æ›´çœŸå®**ã€‚
3.  **å¯å¤ç°æ€§**ï¼š`golden_testset.json` æ–‡ä»¶è¢«ä¿å­˜ä¸‹æ¥äº†ã€‚ä½ å¯ä»¥åŸºäºè¿™ä¸ªå›ºå®šçš„æµ‹è¯•é›†ï¼Œå»å¯¹æ¯”â€œå¾®è°ƒå‰â€å’Œâ€œå¾®è°ƒåâ€çš„æ•ˆæœï¼Œæˆ–è€…â€œåŠ äº† Rerankâ€å’Œâ€œæ²¡åŠ  Rerankâ€çš„æ•ˆæœã€‚è¿™å°±æ˜¯**ç§‘å­¦çš„æ§åˆ¶å˜é‡æ³•**ã€‚