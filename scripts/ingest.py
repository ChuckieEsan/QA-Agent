import os
import sys
import sqlite3
from tqdm import tqdm
from pymilvus import MilvusClient
from sentence_transformers import SentenceTransformer

sys.path.append(os.getcwd())

from app.core.config import settings
from app.utils import generate_doc_id, get_device, clean_text

# ================= é…ç½®åŒºåŸŸ =================
BATCH_SIZE = 16  
MODEL_PATH = str(settings.models.embedding_model_path)
MILVUS_DB_PATH = str(settings.paths.milvus_db_path)
COLLECTION_NAME = settings.vectordb.collection_name
SQLITE_DB_PATH = str(settings.paths.raw_data_db_path)

def init_milvus(client: MilvusClient):
    """åˆå§‹åŒ–æ•°æ®åº“é›†åˆ Schema"""
    if client.has_collection(COLLECTION_NAME):
        print(f"æ£€æµ‹åˆ°é›†åˆ {COLLECTION_NAME} å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤é‡å»º...")
        client.drop_collection(COLLECTION_NAME)

    print("ğŸ”¨ åˆ›å»ºæ–°é›†åˆ Schema...")
    client.create_collection(
        collection_name=COLLECTION_NAME,
        dimension=settings.models.embedding_size, # BGE-M3 ç»´åº¦
        metric_type="COSINE",
        auto_id=True,
        enable_dynamic_field=True 
    )

def fetch_data_from_sqlite(db_path: str):
    """ä» SQLite è¯»å–æ‰€æœ‰å·²çˆ¬å–çš„æ•°æ®"""
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶: {db_path}")
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row # å…è®¸é€šè¿‡åˆ—åè®¿é—®
    cursor = conn.cursor()
    
    # ä»…è¯»å–æœ‰æ ‡é¢˜ã€é—®é¢˜å’Œå›å¤çš„æ•°æ®
    cursor.execute("""
        SELECT id, title, dept, question, answer, question_time, url 
        FROM wenzheng 
        WHERE question IS NOT NULL AND answer IS NOT NULL
    """)
    rows = cursor.fetchall()
    conn.close()
    return rows

def process_and_ingest():
    # 1. è¯»å–æ•°æ®
    try:
        rows = fetch_data_from_sqlite(SQLITE_DB_PATH)
    except Exception as e:
        print(f"âŒ è¯»å– SQLite å¤±è´¥: {e}")
        return

    print(f"ğŸ“– æœ‰æ•ˆæ•°æ®é‡: {len(rows)} æ¡")
    if len(rows) == 0:
        print("âš ï¸ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ crawl.py")
        return

    # 2. åŠ è½½æ¨¡å‹
    device = get_device()
    print(f"ğŸ“¥ åŠ è½½ Embedding æ¨¡å‹: {MODEL_PATH} ...")
    try:
        embed_model = SentenceTransformer(MODEL_PATH, device=device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # 3. åˆå§‹åŒ– Milvus
    os.makedirs(os.path.dirname(MILVUS_DB_PATH), exist_ok=True)
    client = MilvusClient(MILVUS_DB_PATH)
    init_milvus(client)

    # 4. æ‰¹é‡å¤„ç†
    total_rows = len(rows)
    print("ğŸš€ å¼€å§‹å‘é‡åŒ–å¹¶å…¥åº“...")
    
    # å°† sqlite3.Row å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œæ–¹ä¾¿å¤„ç†
    data_list = [dict(row) for row in rows]
    
    for i in tqdm(range(0, total_rows, BATCH_SIZE), desc="Processing"):
        batch = data_list[i : i + BATCH_SIZE]
        
        # å‡†å¤‡ Embedding çš„æ–‡æœ¬ï¼šä¸»è¦ä½¿ç”¨â€œé—®é¢˜â€
        texts_to_embed = [clean_text(item['question']) for item in batch]
        
        # ç”Ÿæˆå‘é‡
        vectors = embed_model.encode(texts_to_embed, normalize_embeddings=True)
        
        data_to_insert = []
        for j, item in enumerate(batch):
            # æ¸…æ´—æ–‡æœ¬
            question_text = clean_text(item['question'])
            answer_text = clean_text(item['answer'])
            title_text = item['title']
            dept_text = item['dept']
            time_text = item['question_time']
            url_text = item['url']
            
            doc_id = generate_doc_id(question_text, answer_text)

            # === æ„å»º RAG ä¸Šä¸‹æ–‡ (Rich Context) ===
            # è¿™é‡ŒåŠ å…¥äº†æ ‡é¢˜ã€æ—¶é—´ã€æ¥æºï¼Œè®©å¤§æ¨¡å‹å›ç­”æ—¶æ›´ä¸“ä¸š
            rag_context = (
                f"æ ‡é¢˜ï¼š{title_text}\n"
                f"éƒ¨é—¨ï¼š{dept_text}\n"
                f"æ—¶é—´ï¼š{time_text}\n"
                f"å¸‚æ°‘è¯‰æ±‚ï¼š{question_text}\n"
                f"å®˜æ–¹å›å¤ï¼š{answer_text}\n"
                f"æ¥æºé“¾æ¥ï¼š{url_text}"
            )
            
            data_to_insert.append({
                "vector": vectors[j],
                "text": rag_context,            
                "department": dept_text,   
                "metadata": {                   
                    "doc_id": doc_id,
                    "crawler_id": item['id'], # åŸå§‹ID
                    "title": title_text,
                    "question": question_text,
                    "answer": answer_text,
                    "url": url_text,
                    "time": time_text
                }
            })
            
        client.insert(COLLECTION_NAME, data_to_insert)

    print(f"\nğŸ‰ å…¥åº“å®Œæˆï¼æ•°æ®åº“: {MILVUS_DB_PATH}")

    # éªŒè¯æµ‹è¯•
    test_query = "é›¨éœ²è®¡åˆ’ä»€ä¹ˆæ—¶å€™å‘ï¼Ÿ"
    print(f"\næµ‹è¯•æ£€ç´¢: '{test_query}'")
    query_vec = embed_model.encode([test_query], normalize_embeddings=True)
    
    res = client.search(
        collection_name=COLLECTION_NAME,
        data=query_vec,
        limit=2,
        output_fields=["text", "department"]
    )
    
    for rank, hit in enumerate(res[0]):
        print(f"\n--- Rank {rank+1} (Score: {hit['distance']:.4f}) ---")
        print(f"éƒ¨é—¨: {hit['entity'].get('department')}")
        print(f"å†…å®¹æ‘˜è¦: {hit['entity'].get('text')[:100]}...")

if __name__ == "__main__":
    process_and_ingest()