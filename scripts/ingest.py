import os
import sys
import pandas as pd
from tqdm import tqdm
from pymilvus import MilvusClient
from sentence_transformers import SentenceTransformer
import torch


# ================= é…ç½®åŒºåŸŸ =================
BATCH_SIZE = 16  
MODEL_PATH = "./models/bge-m3"
DB_PATH = "data/milvus_db/gov_pulse.db"
COLLECTION_NAME = "gov_cases"
DATA_PATH = "data/raw/wzlz_municipal_has_reply.xlsx" 

def get_device():
    if torch.cuda.is_available():
        return "cuda"
    return "cpu"

def init_milvus(client):
    """åˆå§‹åŒ–æ•°æ®åº“é›†åˆ Schema"""
    if client.has_collection(COLLECTION_NAME):
        print(f"æ£€æµ‹åˆ°é›†åˆ {COLLECTION_NAME} å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤é‡å»º...")
        client.drop_collection(COLLECTION_NAME)

    print("ğŸ”¨ åˆ›å»ºæ–°é›†åˆ Schema...")
    client.create_collection(
        collection_name=COLLECTION_NAME,
        dimension=1024, # BGE-M3 ç»´åº¦
        metric_type="COSINE",
        auto_id=True,
        enable_dynamic_field=True 
    )

def process_and_ingest():
    # 1. è¯»å–æ•°æ®
    if not os.path.exists(DATA_PATH):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {DATA_PATH}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        return

    print(f"ğŸ“– è¯»å–æ•°æ®: {DATA_PATH}")
    df = pd.read_excel(DATA_PATH)
    
    # === å…³é”®ä¿®æ”¹ï¼šåˆ—åæ˜ å°„ ===
    # å°†ä½ çš„ Excel ä¸­æ–‡åˆ—åæ˜ å°„ä¸ºä»£ç å˜é‡
    # é€»è¾‘ï¼šåªè¦åŒ…å«è¿™äº›å…³é”®å­—çš„åˆ—ï¼Œå°±é‡å‘½å
    rename_map = {}
    for col in df.columns:
        if "é—®æ”¿å†…å®¹" in col:
            rename_map[col] = "question"
        elif "å›å¤å•ä½" in col:
            rename_map[col] = "department"
        elif "å›å¤å†…å®¹" in col:
            rename_map[col] = "answer"
            
    df = df.rename(columns=rename_map)
    
    # æ£€æŸ¥æ˜¯å¦æ˜ å°„æˆåŠŸ
    required_cols = ['question', 'answer']
    if not all(col in df.columns for col in required_cols):
        print(f"âŒ åˆ—ååŒ¹é…å¤±è´¥ï¼å½“å‰åˆ—å: {df.columns.tolist()}")
        print("è¯·ç¡®ä¿ Excel åŒ…å«ï¼š'é—®æ”¿å†…å®¹' å’Œ 'å›å¤å†…å®¹'")
        return

    # æ¸…æ´—ï¼šå»æ‰æ²¡æœ‰é—®é¢˜æˆ–æ²¡æœ‰å›ç­”çš„æ•°æ®
    df = df.dropna(subset=['question', 'answer'])
    # ç®€å•æ¸…æ´—ï¼šè½¬ä¸ºå­—ç¬¦ä¸²ï¼Œé˜²æ­¢ Excel é‡Œçš„æ•°å­—æŠ¥é”™
    df['question'] = df['question'].astype(str)
    df['answer'] = df['answer'].astype(str)
    df['department'] = df['department'].astype(str)
        
    print(f"æœ‰æ•ˆæ•°æ®é‡: {len(df)} æ¡")

    # 2. åŠ è½½æ¨¡å‹
    device = get_device()
    print(f"ğŸ“¥ åŠ è½½ Embedding æ¨¡å‹: {MODEL_PATH} ...")
    try:
        embed_model = SentenceTransformer(MODEL_PATH, device=device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # 3. åˆå§‹åŒ– Milvus
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    client = MilvusClient(DB_PATH)
    init_milvus(client)

    # 4. æ‰¹é‡å¤„ç†
    total_rows = len(df)
    print("ğŸš€ å¼€å§‹å‘é‡åŒ–å¹¶å…¥åº“...")
    
    for i in tqdm(range(0, total_rows, BATCH_SIZE), desc="Processing"):
        batch = df.iloc[i : i + BATCH_SIZE]
        
        # === å…³é”®ç­–ç•¥ï¼šEmbedding è°ï¼Ÿ===
        # ç­–ç•¥ï¼šæˆ‘ä»¬å‘é‡åŒ–â€œé—®é¢˜â€ï¼ˆAåˆ—ï¼‰ã€‚
        # å› ä¸ºç”¨æˆ·çš„æé—®é€šå¸¸å’Œ A åˆ—æœ€ç›¸ä¼¼ï¼ˆéƒ½æ˜¯æ±‚åŠ©ã€å’¨è¯¢ï¼‰ã€‚
        # å¦‚æœæˆ‘ä»¬å‘é‡åŒ–â€œå›ç­”â€ï¼Œç”¨æˆ·é—®â€œæ€ä¹ˆå–é’±â€ï¼Œå›ç­”æ˜¯â€œæºå¸¦èº«ä»½è¯...â€ï¼Œè¯­ä¹‰åŒ¹é…åº¦åè€Œå¯èƒ½ä¸é«˜ã€‚
        texts_to_embed = batch['question'].tolist()
        
        # å‡†å¤‡å…¶ä»–å­—æ®µ
        answers = batch['answer'].tolist()
        departments = batch['department'].tolist()
        
        # ç”Ÿæˆå‘é‡
        vectors = embed_model.encode(texts_to_embed, normalize_embeddings=True)
        
        data_to_insert = []
        for j, question_text in enumerate(texts_to_embed):
            # === å…³é”®ç­–ç•¥ï¼šRAG ä¸Šä¸‹æ–‡å­˜ä»€ä¹ˆï¼Ÿ===
            # æˆ‘ä»¬æŠŠâ€œé—®é¢˜â€å’Œâ€œå›ç­”â€æ‹¼åœ¨ä¸€èµ·å­˜å…¥ `text` å­—æ®µã€‚
            # è¿™æ ·æ£€ç´¢å‡ºæ¥ç»™å¤§æ¨¡å‹çœ‹çš„æ—¶å€™ï¼Œå¤§æ¨¡å‹èƒ½çœ‹åˆ°å®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚
            rag_context = f"å¸‚æ°‘è¯‰æ±‚ï¼š{question_text}\nå®˜æ–¹å›å¤ï¼š{answers[j]}"
            
            data_to_insert.append({
                "vector": vectors[j],
                "text": rag_context,            # ç»™å¤§æ¨¡å‹çœ‹çš„å†…å®¹
                "department": departments[j],   # è¿‡æ»¤ç”¨çš„æ ‡ç­¾
                "metadata": {                   # åŸå§‹æ•°æ®å¤‡ä»½
                    "question": question_text,
                    "answer": answers[j]
                }
            })
            
        client.insert(COLLECTION_NAME, data_to_insert)

    print(f"\nğŸ‰ å…¥åº“å®Œæˆï¼æ•°æ®åº“: {DB_PATH}")

    # 5. éªŒè¯æµ‹è¯•
    test_query = "é›¨éœ²è®¡åˆ’ä»€ä¹ˆæ—¶å€™å‘ï¼Ÿ"
    print(f"\nğŸ” æµ‹è¯•æ£€ç´¢: '{test_query}'")
    query_vec = embed_model.encode([test_query], normalize_embeddings=True)
    
    res = client.search(
        collection_name=COLLECTION_NAME,
        data=query_vec,
        limit=2,
        output_fields=["text", "department"]
    )
    
    for rank, hit in enumerate(res[0]):
        print(f"\n--- Rank {rank+1} (Score: {hit['distance']:.4f}) ---")
        print(f"éƒ¨é—¨: {hit['entity'].get('department')}")
        print(f"å†…å®¹æ‘˜è¦: {hit['entity'].get('text')[:100]}...")

if __name__ == "__main__":
    process_and_ingest()