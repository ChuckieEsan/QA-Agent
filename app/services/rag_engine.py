"""
RAGåè°ƒå¼•æ“Ž - æ•´åˆæ£€ç´¢å’Œç”Ÿæˆ
"""

import time
from typing import Dict, List, Optional, Tuple
from app.services.retriever import HybridVectorRetriever
from app.services.llm_service import LLMService
from app.core.logger import get_logger

logger = get_logger(__name__)


class RAGEngine:
    """
    RAGåè°ƒå¼•æ“Ž
    èŒè´£ï¼šè°ƒç”¨æ£€ç´¢å™¨ -> è°ƒç”¨LLMç”Ÿæˆ -> è¿”å›žå®Œæ•´ç»“æžœ
    """
    
    def __init__(self):
        self.retriever = HybridVectorRetriever()
        self.llm_service = LLMService()
        logger.info("ðŸ”„ RAGå¼•æ“Žåˆå§‹åŒ–å®Œæˆ")
    
    async def query(
        self, 
        query: str, 
        top_k: int = 5,
        history: List[Dict] = None,
        stream: bool = False
    ) -> Dict[str, any]:
        """
        å®Œæ•´çš„RAGæŸ¥è¯¢æµç¨‹
        
        Returns:
            {
                "answer": str,               # ç”Ÿæˆçš„å›žç­”
                "sources": List[Dict],       # æ£€ç´¢åˆ°çš„æ¥æº
                "context": str,              # æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
                "metadata": Dict[str, any],  # å…ƒæ•°æ®
                "generation_metrics": Dict   # ç”Ÿæˆç›¸å…³æŒ‡æ ‡
            }
        """
        start_time = time.time()
        
        # 1. æ£€ç´¢é˜¶æ®µ
        logger.info(f"ðŸ” æ£€ç´¢æŸ¥è¯¢: {query}")
        context_str, results, metadata = self.retriever.retrieve(query, top_k)
        
        retrieval_time = time.time() - start_time
        logger.info(f"âœ… æ£€ç´¢å®Œæˆï¼Œè€—æ—¶: {retrieval_time:.2f}sï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æžœ")
        
        # 2. ç”Ÿæˆé˜¶æ®µ
        logger.info(f"ðŸ¤– å¼€å§‹ç”Ÿæˆå›žç­”...")
        generation_start = time.time()
        
        if stream:
            # æµå¼ç”Ÿæˆ
            return await self._stream_generation(query, context_str, results, metadata, history)
        else:
            # æ™®é€šç”Ÿæˆ
            generation_result = await self.llm_service.generate_response(
                query=query,
                context=context_str,
                history=history
            )
        
        generation_time = time.time() - generation_start
        
        # 3. æ•´åˆç»“æžœ
        total_time = time.time() - start_time
        
        return {
            "query": query,
            "answer": generation_result["answer"],
            "sources": results[:top_k],
            "context": context_str,
            "metadata": {
                **metadata,
                "retrieval_time": retrieval_time,
                "generation_time": generation_time,
                "total_time": total_time,
                "model": generation_result.get("model", "unknown"),
                "token_usage": generation_result.get("usage", {})
            },
            "generation_metrics": generation_result
        }
    
    async def _stream_generation(self, query, context, results, metadata, history):
        """æµå¼ç”Ÿæˆå¤„ç†"""
        # å®žçŽ°æµå¼ç”Ÿæˆé€»è¾‘
        raise NotImplementedError("æµå¼ç”Ÿæˆå°šæœªå®žçŽ°")


# å·¥å…·å‡½æ•°
async def query_rag(query: str, top_k: int = 5) -> Dict[str, any]:
    """å¿«é€ŸRAGæŸ¥è¯¢"""
    engine = RAGEngine()
    return await engine.query(query, top_k)